import { SectionTab } from '@/components/layout/section-tab';

# Chat Completions

LLMs are models capable of text generation, they also allow you to chat with a model that has been fine-tuned to **follow
instructions and respond to natural language prompts**.
A prompt is the input that you provide to the Mistral model.
It can come in various forms, such as asking a question, giving an instruction,
or providing a few examples of the task you want the model to perform.
Based on the prompt, the model generates a text output as a response.

<Image
  url={['/img/chat_completions.png', '/img/chat_completions_dark.png']}
  alt="chat_completions_graph"
  width="500px"
  centered
/>

The use cases around Text Generation such as Chat Completions are endless and can be applied to a wide range of applications.
From:
- Chatbots
- Classification
- Data Extraction
- Text Summarization
- Code Generation
- Question Answering

And much more!

<SectionTab as="h1" sectionId="learn-more">Learn More</SectionTab>

- [Usage](completion/usage): Learn how to use the Chat Completions API to generate text powered by instruction following.
- [Prompting](completion/prompting): Learn how to write prompts to get the best results from Chat Completions and our models.
- [Sampling](completion/sampling): Learn how to control and steer the randomness of the generated text.