import { SectionTab } from '@/components/layout/section-tab';
import { Tabs, TabItem } from '@/components/common/multi-codeblock';

A batch file for embeddings, with `v1/embeddings` as the Endpoint and `mistral-embed` as the Model, would look like the following:

<Tabs groupId="code">
    <TabItem value="file" label="Batch File" default>

```bash
{"custom_id": "0", "body": {"input": ["The quick brown fox jumps over the lazy dog.", "To be or not to be, that is the question."]}}
{"custom_id": "1", "body": {"input": "Success is not final, failure is not fatal: It is the courage to continue that counts."}}
{"custom_id": "2", "body": {"input": ["The only way to do great work is to love what you do.", "In the middle of every difficulty lies opportunity.", "Knowledge is power, but enthusiasm pulls the switch."]}}
```

    </TabItem>
    <TabItem value="output" label="Result File">

```bash
{"id":"batch-089b0faa-1-d4475954-11af-4b2b-a819-091cf96a33d1","custom_id":"0","response":{"status_code":200,"body":{"id":"9e9bc2cc688a4dfb8cf4088c1d687392","object":"list","model":"mistral-embed","usage":{"prompt_tokens":28,"completion_tokens":0,"total_tokens":28,"prompt_audio_seconds":null,"prompt_token_details":null,"request_count":null},"data":[{"object":"embedding","embedding":[-0.013092041015625,0.034088134765625,0.03546142578125,0.00879669189453125,0.0399169921875,0.0236968994140625,0.0245208740234375...862884521484375,-0.034759521484375,-0.0118560791015625,-0.006099700927734375,-0.002819061279296875,0.054779052734375,0.0007371902465820312,0.04718017578125,-0.01219940185546875,0.010009765625,-0.052490234375,0.0004892349243164062,-0.0157623291015625,-0.01214599609375,0.0223236083984375,-0.017730712890625,-0.03912353515625,0.0423583984375,0.03546142578125,0.04052734375,-0.006244659423828125,0.0545654296875,0.02001953125,-0.034515380859375,-0.00839996337890625,-0.0088043212890625],"index":1}]}},"error":null}
{"id":"batch-089b0faa-2-b9d5c3ce-433c-46f1-a13f-e0e4a763b52f","custom_id":"1","response":{"status_code":200,"body":{"id":"a67f9a3b35a845999e6ae30af5b79cd4","object":"list","model":"mistral-embed","usage":{"prompt_tokens":21,"completion_tokens":0,"total_tokens":21,"prompt_audio_seconds":null,"prompt_token_details":null,"request_count":null},"data":[{"object":"embedding","embedding":[-0.0202789306640625,0.045196533203125,0.0191192626953125,0.0228118896484375,0.0267181396484375,0.037811279296875,0.036315917968...8515625,-0.01129913330078125,-0.01177215576171875,-0.0006928443908691406,-0.026824951171875,0.0352783203125,-0.0063629150390625,0.040985107421875,0.0025482177734375,0.018798828125,-0.07769775390625,-0.0225982666015625,-0.0212249755859375,-0.0194244384765625,0.029998779296875,-0.046478271484375,-0.053863525390625,0.0173187255859375,0.0439453125,0.00844573974609375,-0.0065460205078125,0.03948974609375,0.0216522216796875,-0.01267242431640625,0.013519287109375,-0.004276275634765625],"index":0}]}},"error":null}
{"id":"batch-089b0faa-3-9b701be0-78c3-4066-9b9c-8746db3d5fee","custom_id":"2","response":{"status_code":200,"body":{"id":"4bb65979fcd143fca01a559837577dfe","object":"list","model":"mistral-embed","usage":{"prompt_tokens":40,"completion_tokens":0,"total_tokens":40,"prompt_audio_seconds":null,"prompt_token_details":null,"request_count":null},"data":[{"object":"embedding","embedding":[-0.0277099609375,0.0562744140625,-0.0008287429809570312,0.0001367330551147461,-0.0126190185546875,-0.0201873779296875,0.0575561...41796875,0.02294921875,-0.019439697265625,0.026611328125,0.004222869873046875,0.063720703125,-0.0037841796875,0.0011205673217773438,0.021514892578125,0.004978179931640625,-0.08990478515625,0.0164947509765625,0.01020050048828125,0.01171112060546875,0.00856781005859375,-0.0011301040649414062,-0.03155517578125,0.033294677734375,0.033477783203125,0.023590087890625,-0.014739990234375,0.04718017578125,0.020721435546875,-0.0180816650390625,-0.002002716064453125,-0.00010335445404052734],"index":2}]}},"error":null}
```

    </TabItem>
</Tabs>

As a JSONL file, each line represents a request to the API Endpoint and Model.

<SectionTab as="h2" variant="secondary" sectionId="embeddings-explained">Explanation</SectionTab>

The body request will follow the same format as the endpoint you want to run your batching, except the model id that will be provided only during the job creation to start the batch run. Below we provide an example of row with embeddings:

```py
{
    "custom_id": "2", # An ID as metadata that will be returned in the output file to identify the request
    "body": { # The body of the request
        "input": [ # The input text to embed, can be a string or an array of strings
            "The only way to do great work is to love what you do.", 
            "In the middle of every difficulty lies opportunity.", 
            "Knowledge is power, but enthusiasm pulls the switch."
        ]
    }
}
```

For more information regarding embeddings, visit the [Embeddings](embeddings) docs and the corresponding [API Spec](../api/endpoint/embeddings#operation-embeddings_v1_embeddings_post).