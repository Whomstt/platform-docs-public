import { SectionTab } from '@/components/layout/section-tab';

# Fine-tuning

:::warning[ ]
Every fine-tuning job comes with a minimum fee of $4, and there's a monthly storage fee of $2 for each model. For more detailed pricing information, please visit our [pricing page](https://mistral.ai/technology/#pricing).
:::

<SectionTab as="h1" sectionId="fine-tuning-vs-prompting">Fine-tuning vs. Prompting</SectionTab>

When deciding whether to use prompt engineering or fine-tuning for an AI model, it can be difficult to determine which method is best. It's generally recommended to start with prompt engineering, as it's faster and less resource-intensive. To help you choose the right approach, here are the key benefits of prompting and fine-tuning:

<SectionTab as="h2" variant="secondary" sectionId="benefits-of-prompting" variant="secondary">Benefits of Prompting</SectionTab>
  - A generic model can work out of the box (the task can be described in a zero shot fashion)
  - Does not require any fine-tuning data or training to work
  - Can easily be updated for new workflows and prototyping

  Check out our [prompting doc](completion/prompting_capabilities) to explore various prompting methods to leverage Mistral models.

<SectionTab as="h2" variant="secondary" sectionId="benefits-of-fine-tuning" variant="secondary">Benefits of Fine-tuning</SectionTab>
  - Works significantly better than prompting
  - Typically works better than a larger model (faster and cheaper because it doesn't require a very long prompt)
  - Provides a better alignment with the task of interest because it has been specifically trained on these tasks
  - Can be used to teach new facts and information to the model (such as advanced tools or complicated workflows)

<SectionTab as="h2" variant="secondary" sectionId="fine-tuning-vs-prompting">Common use cases</SectionTab>

Fine-tuning has a wide range of use cases, some of which include:

- Customizing the model to generate responses in a specific format and tone
- Specializing the model for a specific topic or domain to improve its performance on domain-specific tasks
- Improving the model through distillation from a stronger and more powerful model by training it to mimic the behavior of the larger model
- Enhancing the modelâ€™s performance by mimicking the behavior of a model with a complex prompt, but without the need for the actual prompt, thereby saving tokens, and reducing associated costs
- Reducing cost and latency by using a small yet efficient fine-tuned model

<SectionTab as="h1" sectionId="fine-tuning-vs-prompting">Fine-tuning Services</SectionTab>
- [Text & Vision General Fine-tuning](finetuning/text_vision_finetuning) via SFT: Supervised Fine-tuning, the most common fine-tuning method to teach the model knowledge and how to follow instructions.
- [Classifier Factory](finetuning/classifier_factory): A tool to finetune and create classifier specific models from a dataset of text.
