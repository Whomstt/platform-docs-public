import { SectionTab } from '@/components/layout/section-tab';

# Embeddings

**Embeddings** are **vector representations** of text that capture the **semantic meaning** of paragraphs through their position in a high-dimensional vector space. Mistral AI's Embeddings API offers cutting-edge, state-of-the-art embeddings for text and code, which can be used for many natural language processing (NLP) tasks.

<Image
  url={['/img/embedding_graph.png', '/img/embedding_graph_dark.png']}
  alt="embedding_graph"
  width="500px"
  centered
/>

Among the vast array of use cases for embeddings are **retrieval systems** powering **retrieval-augmented generation**, **clustering** of unorganized data, **classification** of vast amounts of documents, **semantic code search** to explore databases and repositories, **code analytics**, **duplicate detection**, and various kinds of search when dealing with multiple sources of raw text or code.

<SectionTab as="h1" sectionId="services">Services</SectionTab>

We provide two state-of-the-art embeddings:
- [Text Embeddings](embeddings/text_embeddings): For embedding a wide variety of text, a general-purpose, efficient embedding model.
- [Code Embeddings](embeddings/code_embeddings): Specially designed for code, perfect for embedding code databases, repositories, and powering coding assistants with state-of-the-art retrieval.

We will cover the fundamentals of the embeddings API, including how to measure the distance between text embeddings, and explore two main use cases: clustering and classification.

<SectionTab as="h2" variant="secondary" sectionId="services">More</SectionTab>
For a quick example and introduction on how to leverage embeddings for RAG (Retrieval-Augmented Generation), check out our [RAG Quickstart](embeddings/rag_quickstart).